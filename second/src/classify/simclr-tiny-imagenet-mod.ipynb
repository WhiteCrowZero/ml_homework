{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":109264,"sourceType":"datasetVersion","datasetId":56828}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# SimCLR ‚Äî Tiny-ImageNet (Modded)\nModifikasi yang diterapkan:\n1. **Augmentasi tambahan**: `RandomAffine`, `RandomSolarize`, `RandomEqualize`.\n2. **Backbone baru**: support `resnet34` selain `resnet18`/`resnet50`.\n3. **Projection head**: `Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Linear`.\n4. **Hyperparameter**: temperature diset `0.2` (mudah diubah).\n5. **Output visual**: plot **loss**, **t-SNE**, dan **PCA**.\n\n> Catatan: Pastikan path dataset **Tiny-ImageNet** sesuai dengan lingkungan Anda.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport sys\nimport csv\nimport yaml\nimport math\nimport random\n\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\nimport torchvision\nfrom torchvision import datasets, models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import transforms, InterpolationMode\n\nimport torch.backends.cudnn as cudnn\n\n# Reproducibility\ntorch.manual_seed(0)\nnp.random.seed(0)\nrandom.seed(0)\n\nprint(\"PyTorch:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:42.713533Z","iopub.execute_input":"2025-08-26T17:33:42.714081Z","iopub.status.idle":"2025-08-26T17:33:50.751916Z","shell.execute_reply.started":"2025-08-26T17:33:42.714059Z","shell.execute_reply":"2025-08-26T17:33:50.751123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GaussianBlur(object):\n    \"\"\"blur a single image on CPU\"\"\"\n    def __init__(self, kernel_size):\n        radias = kernel_size // 2\n        kernel_size = radias * 2 + 1\n        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n                                stride=1, padding=0, bias=False, groups=3)\n        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n                                stride=1, padding=0, bias=False, groups=3)\n        self.k = kernel_size\n        self.r = radias\n\n        self.blur = nn.Sequential(\n            nn.ReflectionPad2d(radias),\n            self.blur_h,\n            self.blur_v\n        )\n\n        self.pil_to_tensor = transforms.ToTensor()\n        self.tensor_to_pil = transforms.ToPILImage()\n\n    def __call__(self, img):\n        img = self.pil_to_tensor(img).unsqueeze(0)\n\n        sigma = np.random.uniform(0.1, 2.0)\n        x = np.arange(-self.r, self.r + 1)\n        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n        x = x / x.sum()\n        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n\n        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n\n        with torch.no_grad():\n            img = self.blur(img)\n            img = img.squeeze()\n\n        img = self.tensor_to_pil(img)\n        return img\n\n\ndef save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, 'model_best.pth.tar')\n\n\ndef save_config_file(model_checkpoints_folder, args):\n    if not os.path.exists(model_checkpoints_folder):\n        os.makedirs(model_checkpoints_folder)\n        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n            yaml.dump(args, outfile, default_flow_style=False)\n\n\ndef accuracy(output, target, topk=(1,)):\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\nclass BaseSimCLRException(Exception):\n    pass\n\n\nclass InvalidBackboneError(BaseSimCLRException):\n    pass\n\n\nclass InvalidDatasetSelection(BaseSimCLRException):\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:50.753441Z","iopub.execute_input":"2025-08-26T17:33:50.753794Z","iopub.status.idle":"2025-08-26T17:33:50.765243Z","shell.execute_reply.started":"2025-08-26T17:33:50.753775Z","shell.execute_reply":"2025-08-26T17:33:50.764562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# augmentasi\nkode ini bertugas memperkaya variasi data gambar sebelum masuk ke model. Proses augmentasi meliputi transformasi seperti crop acak, rotasi, flipping, perubahan warna, hingga normalisasi. Tujuannya adalah membuat model lebih robust terhadap berbagai kondisi input dan mencegah overfitting, karena model belajar dari beragam variasi gambar meskipun berasal dari dataset yang sama.","metadata":{}},{"cell_type":"code","source":"class ContrastiveLearningViewGenerator(object):\n    \"\"\"Generate two random views of one image\"\"\"\n    def __init__(self, base_transform, n_views=2):\n        self.base_transform = base_transform\n        self.n_views = n_views\n\n    def __call__(self, x):\n        return [self.base_transform(x) for _ in range(self.n_views)]\n\n\nclass ContrastiveLearningDataset:\n    def __init__(self, root_folder):\n        self.root_folder = root_folder\n\n    @staticmethod\n    def get_simclr_pipeline_transform(size, s=1):\n        \"\"\"Augmentasi (modifikasi): tambah RandomAffine, Solarize, Equalize\"\"\"\n        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n        data_transforms = transforms.Compose([\n            transforms.RandomResizedCrop(size=size, interpolation=InterpolationMode.BICUBIC),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomApply([color_jitter], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            GaussianBlur(kernel_size=int(0.1 * size)),\n            # --- tambahan ---\n            transforms.RandomAffine(degrees=20, translate=(0.1, 0.1)),\n            transforms.RandomSolarize(threshold=128, p=0.2),\n            transforms.RandomEqualize(p=0.2),\n            transforms.ToTensor(),\n            \n        \n        ])\n        return data_transforms\n\n    def get_dataset(self, name, n_views):\n        valid_datasets = {\n            'cifar10': lambda: datasets.CIFAR10(self.root_folder, train=True,\n                                                transform=ContrastiveLearningViewGenerator(\n                                                    self.get_simclr_pipeline_transform(32),\n                                                    n_views),\n                                                download=True),\n            'stl10': lambda: datasets.STL10(self.root_folder, split='unlabeled',\n                                            transform=ContrastiveLearningViewGenerator(\n                                                self.get_simclr_pipeline_transform(96),\n                                                n_views),\n                                            download=True),\n            'tinyimagenet': lambda: ImageFolder(\n                root=os.path.join(self.root_folder, 'tiny-imagenet-200', 'train'),\n                transform=ContrastiveLearningViewGenerator(\n                    self.get_simclr_pipeline_transform(64),\n                    n_views))\n        }\n        try:\n            dataset_fn = valid_datasets[name]\n        except KeyError:\n            raise InvalidDatasetSelection()\n        else:\n            return dataset_fn()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:50.765985Z","iopub.execute_input":"2025-08-26T17:33:50.766206Z","iopub.status.idle":"2025-08-26T17:33:50.787152Z","shell.execute_reply.started":"2025-08-26T17:33:50.76619Z","shell.execute_reply":"2025-08-26T17:33:50.786379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# backbone encoder dan projection head\nEncoder ini mengubah gambar mentah menjadi representasi fitur berdimensi tinggi yang lebih bermakna. Fitur inilah yang nantinya digunakan untuk proses pembelajaran representasi. Backbone biasanya dipilih yang sudah teruji performanya, sehingga hasil ekstraksi fitur lebih optimal.\n\nKemudian pada projection head, lapisan tambahan berupa multilayer perceptron (MLP) digunakan untuk memetakan fitur hasil encoder ke ruang embedding yang lebih kecil. Ruang ini berguna untuk membandingkan kemiripan antar sampel dalam proses contrastive learning. Dengan adanya projection head, representasi fitur menjadi lebih terstruktur dan siap digunakan untuk perhitungan loss.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\n\nclass ResNetSimCLR(nn.Module):\n    def __init__(self, base_model, out_dim):\n        super(ResNetSimCLR, self).__init__()\n        self.resnet_dict = {\n            \"resnet18\": models.resnet18(weights=None),\n            \"resnet34\": models.resnet34(weights=None),   # backbone baru\n            \"resnet50\": models.resnet50(weights=None),\n        }\n        self.backbone = self._get_basemodel(base_model)\n        dim_mlp = self.backbone.fc.in_features\n\n # Projection head baru: Linear -> BN -> ReLU -> Linear(out_dim)\n        self.backbone.fc = nn.Sequential(\n        nn.Linear(dim_mlp, dim_mlp*2),\n        nn.BatchNorm1d(dim_mlp*2),\n        nn.ReLU(inplace=True),\n        nn.Linear(dim_mlp*2, args.out_dim)\n    )\n\n\n    def _get_basemodel(self, model_name):\n        try:\n            model = self.resnet_dict[model_name]\n        except KeyError:\n            raise InvalidBackboneError(\"Backbone invalid. Gunakan resnet18, resnet34, atau resnet50.\")\n        else:\n            return model\n\n    def forward(self, x):\n        return self.backbone(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:50.78786Z","iopub.execute_input":"2025-08-26T17:33:50.788103Z","iopub.status.idle":"2025-08-26T17:33:50.801084Z","shell.execute_reply.started":"2025-08-26T17:33:50.788087Z","shell.execute_reply":"2025-08-26T17:33:50.800418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# loss function\nberbasis contrastive, seperti NT-Xent Loss. Loss ini mengukur seberapa mirip representasi dua gambar augmentasi dari gambar yang sama dibandingkan dengan gambar lain. Jika representasi dua augmentasi dari gambar yang sama semakin dekat, loss akan semakin kecil. Mekanisme ini melatih model untuk mengelompokkan representasi yang relevan dan menjauhkan yang tidak relevan.","metadata":{}},{"cell_type":"code","source":"class SimCLR:\n    def __init__(self, model, optimizer, scheduler, args):\n        self.model = model.to(args.device)\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.args = args\n\n    def nt_xent_loss(self, z1, z2, temperature=0.5):\n        z1 = F.normalize(z1, dim=1)\n        z2 = F.normalize(z2, dim=1)\n        N = z1.size(0)\n        z = torch.cat([z1, z2], dim=0)  # [2N, D]\n        sim = torch.matmul(z, z.t())    # [2N, 2N]\n        mask = torch.eye(2 * N, dtype=torch.bool, device=z.device)\n        sim = sim[~mask].view(2 * N, 2 * N - 1)\n        pos = torch.sum(z1 * z2, dim=-1)\n        pos = torch.cat([pos, pos], dim=0)\n        sim = sim / temperature\n        denom = torch.logsumexp(sim, dim=1)\n        loss = -pos / temperature + denom\n        return loss.mean()\n\n    def train(self, train_loader):\n        self.model.train()\n        loss_history = []\n        for epoch in range(1, self.args.epochs + 1):\n            running = 0.0\n            for step, (views, _) in enumerate(train_loader, start=1):\n                x1, x2 = views\n                x1, x2 = x1.to(self.args.device), x2.to(self.args.device)\n                z1 = self.model(x1)\n                z2 = self.model(x2)\n                loss = self.nt_xent_loss(z1, z2, temperature=self.args.temperature)\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                running += loss.item()\n                if step % self.args.log_every_n_steps == 0:\n                    print(f\"Epoch {epoch}/{self.args.epochs} Step {step}/{len(train_loader)} Loss {running/self.args.log_every_n_steps:.4f}\")\n                    running = 0.0\n            self.scheduler.step()\n            loss_history.append(loss.item())\n            print(f\"[Epoch {epoch}] Loss: {loss.item():.4f}\")\n        return loss_history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:50.802549Z","iopub.execute_input":"2025-08-26T17:33:50.802802Z","iopub.status.idle":"2025-08-26T17:33:50.817189Z","shell.execute_reply.started":"2025-08-26T17:33:50.802775Z","shell.execute_reply":"2025-08-26T17:33:50.816624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# training loop\nproses pelatihan dilakukan secara iteratif dalam beberapa epoch. Di setiap iterasi, batch data diambil, diaugmentasi, diekstraksi fiturnya oleh backbone encoder, lalu diproyeksikan oleh projection head. Kemudian loss dihitung dan bobot model diperbarui menggunakan optimizer. Proses ini diulang terus hingga model belajar menghasilkan representasi yang stabil dan berkualitas.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom types import SimpleNamespace\nimport torch.backends.cudnn as cudnn\nfrom torchvision import datasets, transforms\n\n# ======================\n# Setup Argumen\n# ======================\nargs = SimpleNamespace()\nargs.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# Ganti path dataset Tiny-ImageNet kalau berbeda\n# Struktur: tiny-imagenet-200/{train, val}\nargs.data = '/kaggle/input/tiny-imagenet'\n\ncudnn.deterministic = True\ncudnn.benchmark = True\n\nargs.dataset_name = 'tinyimagenet'\nargs.n_views = 2\nargs.batch_size = 512\nargs.out_dim = 256\nargs.lr = 0.0003\nargs.weight_decay = 1e-4\nargs.arch = 'resnet50'   # bisa diganti 'resnet18'\nargs.workers = 2\nargs.gpu_index = 0\nargs.log_dir = './logs/simclr'\nargs.fp16_precision = True\nargs.epochs = 10\nargs.temperature = 0.5\nargs.seed = 1\nargs.log_every_n_steps = 50\n\n# ======================\n# Dataset\n# ======================\ndataset = ContrastiveLearningDataset(args.data)\n\n# Train dataset (self-supervised pretraining)\ntrain_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=min(args.batch_size, 512),   # 512 disarankan\n    shuffle=True,\n    num_workers=max(2, args.workers, 4),    # 4‚Äì8 biasanya oke di P100\n    pin_memory=True,\n    persistent_workers=True,\n    prefetch_factor=4,\n    drop_last=True\n)\n\n# Validation dataset (evaluasi setelah training)\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n])\n\n# Path val Tiny-ImageNet\nval_dataset = datasets.ImageFolder(root=f\"{args.data}/tiny-imagenet-200/val\", transform=val_transform)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset,\n    batch_size=args.batch_size,\n    shuffle=False,\n    num_workers=args.workers,\n    pin_memory=True\n)\n\n# ======================\n# Model + Optimizer + Scheduler\n# ======================\nmodel = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\noptimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n\n# Cosine LR scheduler\ntotal_steps = args.epochs * len(train_loader)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n\n\n# ======================\n# Training SimCLR\n# ======================\nsimclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n\n# Pretraining di train_loader\nloss_history = simclr.train(train_loader)\n\n# ======================\n# (Optional) Evaluasi pakai val_loader\n# ======================\n# Contoh evaluasi: ambil embedding dan hitung loss / akurasi kNN\n# val_loss = simclr.evaluate(val_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T17:33:50.817986Z","iopub.execute_input":"2025-08-26T17:33:50.818222Z","iopub.status.idle":"2025-08-27T00:19:59.226885Z","shell.execute_reply.started":"2025-08-26T17:33:50.818206Z","shell.execute_reply":"2025-08-27T00:19:59.22586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplt.figure()\nplt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss ‚Äî SimCLR (Modded)\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:19:59.228682Z","iopub.execute_input":"2025-08-27T00:19:59.22897Z","iopub.status.idle":"2025-08-27T00:19:59.46118Z","shell.execute_reply.started":"2025-08-27T00:19:59.228934Z","shell.execute_reply":"2025-08-27T00:19:59.460402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import InterpolationMode\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport shutil\nfrom pathlib import Path\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom sklearn.model_selection import train_test_split\n\n# ============================================================\n# üîπ 1. Ekstraksi fitur backbone (pra-projection)\n# ============================================================\n@torch.no_grad()\ndef extract_backbone_features(model, x):\n    \"\"\"Ambil fitur sebelum projection head (h).\"\"\"\n    old_fc = model.backbone.fc       # ‚úÖ ambil fc dari backbone\n    model.backbone.fc = nn.Identity()\n    h = model.backbone(x)            # ‚úÖ forward backbone\n    model.backbone.fc = old_fc       # balikin fc\n    return h\n\n\n@torch.no_grad()\ndef collect_features_backbone(dataloader, model, device, max_batches=None):\n    \"\"\"\n    Kumpulkan fitur backbone (pra-projection head) dari dataset.\n    - dataloader: ImageFolder return (x, y)\n    - model: SimCLR backbone\n    \"\"\"\n    model.eval()\n    feats, labels = [], []\n    for i, (inputs, y) in enumerate(dataloader, start=1):\n        x = inputs.to(device)\n        h = extract_backbone_features(model, x)  # ‚úÖ backbone features\n        feats.append(h.cpu())\n        labels.append(y)\n        if max_batches is not None and i >= max_batches:\n            break\n    return torch.cat(feats).numpy(), torch.cat(labels).numpy()\n\n\n\n# ============================================================\n# üîπ 2. Transformasi evaluasi sederhana\n# ============================================================\neval_tf = transforms.Compose([\n    transforms.Resize((64, 64), interpolation=InterpolationMode.BICUBIC),\n    transforms.ToTensor()\n])\n\n# ============================================================\n# üîπ 3. Load dataset Tiny-ImageNet val ‚Üí ImageFolder style\n# ============================================================\ndata_root = args.data\nval_images = os.path.join(data_root, \"tiny-imagenet-200\", \"val\", \"images\")\n\nif os.path.isdir(val_images):\n    print(\"üîß Menyiapkan val set...\")\n\n    val_dir = Path(data_root) / \"tiny-imagenet-200/val\"\n    ann_file = val_dir / \"val_annotations.txt\"\n    target_base = Path(\"/kaggle/working/val_split\")\n    target_base.mkdir(exist_ok=True)\n\n    # bikin struktur val_split/class_name/*.JPEG (sekali saja)\n    if not any(target_base.iterdir()):\n        with open(ann_file, \"r\") as f:\n            for line in f:\n                parts = line.strip().split(\"\\t\")\n                img_name, class_name = parts[0], parts[1]\n                class_dir = target_base / class_name\n                class_dir.mkdir(exist_ok=True)\n                shutil.copy(val_dir / \"images\" / img_name, class_dir / img_name)\n\n    val_images = target_base\nelse:\n    print(\"‚ö†Ô∏è val/images tidak ditemukan, fallback pakai train/\")\n    val_images = os.path.join(data_root, \"tiny-imagenet-200\", \"train\")\n\n# ============================================================\n# üîπ 4. Dataset & Dataloader\n# ============================================================\nval_ds = ImageFolder(str(val_images), transform=eval_tf)\nval_loader = torch.utils.data.DataLoader(val_ds, batch_size=512, shuffle=False, num_workers=args.workers)\n\n# ============================================================\n# üîπ 5. Ekstraksi fitur backbone\n# ============================================================\nfeats, labels = collect_features_backbone(val_loader, model, args.device, max_batches=20)\n\n# ============================================================\n# üîπ 6. Visualisasi t-SNE & PCA\n# ============================================================\n# t-SNE\ntsne = TSNE(n_components=2, perplexity=30, n_iter=500, verbose=1, init=\"pca\", learning_rate=\"auto\")\nemb_tsne = tsne.fit_transform(feats)\nplt.figure()\nplt.scatter(emb_tsne[:, 0], emb_tsne[:, 1], c=labels, s=5, alpha=0.6)\nplt.title(\"t-SNE of backbone features (h)\")\nplt.xlabel(\"dim 1\"); plt.ylabel(\"dim 2\")\nplt.show()\n\n# PCA\npca = PCA(n_components=2)\nemb_pca = pca.fit_transform(feats)\nplt.figure()\nplt.scatter(emb_pca[:, 0], emb_pca[:, 1], c=labels, s=5, alpha=0.6)\nplt.title(\"PCA of backbone features (h)\")\nplt.xlabel(\"PC 1\"); plt.ylabel(\"PC 2\")\nplt.show()\n\n# ============================================================\n# üîπ 7. Evaluasi Kuantitatif (Linear Probe & k-NN)\n# ============================================================\n# NOTE: idealnya pakai split train/val. \n# Kalau dataset train tersedia, ganti val_loader jadi train_loader untuk Xtr/Ytr.\n# Di sini contoh: kita pakai val saja untuk demonstrasi (train=val).\n# ‚úÖ Perbaikan: bagi data train/test agar tidak overfitting\nXtr, Xte, Ytr, Yte = train_test_split(\n    feats, labels, test_size=0.2, random_state=42, stratify=labels\n)\n\nscaler = StandardScaler(with_mean=True, with_std=True)\nXtr_s = scaler.fit_transform(Xtr)\nXte_s = scaler.transform(Xte)\n\n# Linear Probe (LogReg)\nclf = LogisticRegression(max_iter=2000, n_jobs=-1, multi_class=\"multinomial\")\nclf.fit(Xtr_s, Ytr)\nprint(\"Linear probe acc:\", accuracy_score(Yte, clf.predict(Xte_s)))\n\n# k-NN dengan cosine distance\nknn = KNeighborsClassifier(n_neighbors=20, metric=\"cosine\")\nknn.fit(Xtr_s, Ytr)\nprint(\"kNN acc:\", accuracy_score(Yte, knn.predict(Xte_s)))\n\n\n\n# ============================================================\n# üîπ 8. Catatan tuning (opsional)\n# ============================================================\n#Tips eksperimen:\n#- Temperature sweep: coba args.temperature = 0.5 (default 0.5 biasanya stabil), lalu bandingkan 0.3 / 0.7.\n#- Augmentasi: kurangi solarize/equalize (p=0.05‚Äì0.1), random affine derajat kecil.\n#- Projection head: gunakan MLP 2-layer + BatchNorm (contoh di bawah):\n\nout_dim = 256  \n\n# Backbone ResNet50 tanpa pretrained\nbackbone = resnet50(weights=None)\n\ndim_mlp = backbone.fc.in_features  # ambil dimensi feature terakhir\n\nbackbone.fc = nn.Sequential(\n    nn.Linear(dim_mlp, dim_mlp*2),\n    nn.BatchNorm1d(dim_mlp*2),\n    nn.ReLU(inplace=True),\n    nn.Linear(dim_mlp*2, out_dim)\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:19:59.462114Z","iopub.execute_input":"2025-08-27T00:19:59.462407Z","iopub.status.idle":"2025-08-27T00:26:20.400128Z","shell.execute_reply.started":"2025-08-27T00:19:59.462381Z","shell.execute_reply":"2025-08-27T00:26:20.399431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train unique labels:\", np.unique(Ytr))\nprint(\"Val unique labels:\", np.unique(Yte))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T00:26:20.401116Z","iopub.execute_input":"2025-08-27T00:26:20.4014Z","iopub.status.idle":"2025-08-27T00:26:20.407498Z","shell.execute_reply.started":"2025-08-27T00:26:20.401351Z","shell.execute_reply":"2025-08-27T00:26:20.40678Z"}},"outputs":[],"execution_count":null}]}